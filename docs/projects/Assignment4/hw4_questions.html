<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jesus Gonzalez">
<meta name="dcterms.date" content="2024-05-30">

<title>Jesus Gonzalez - Key Drivers Analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-B730JHHC8P"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-B730JHHC8P', { 'anonymize_ip': false});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"interstitial",
  "consent_type":"implied",
  "palette":"dark",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Jesus Gonzalez</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">1. Introduction</a></li>
  <li><a href="#data-description" id="toc-data-description" class="nav-link" data-scroll-target="#data-description">2. Data Description</a></li>
  <li><a href="#methods-for-calculating-feature-importance" id="toc-methods-for-calculating-feature-importance" class="nav-link" data-scroll-target="#methods-for-calculating-feature-importance">3. Methods for Calculating Feature Importance</a></li>
  <li><a href="#comparative-analysis" id="toc-comparative-analysis" class="nav-link" data-scroll-target="#comparative-analysis">4. Comparative Analysis</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">5. Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Key Drivers Analysis</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jesus Gonzalez </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 30, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">1. Introduction</h3>
<section id="overview" class="level4">
<h4 class="anchored" data-anchor-id="overview">Overview</h4>
<p>In today’s competitive financial landscape, understanding the factors that drive customer satisfaction with payment cards is crucial for businesses. This article delves into the analysis of survey data collected to gauge customer perceptions and satisfaction related to various aspects of payment cards. By examining these perceptions, companies can better tailor their offerings to meet customer needs and enhance satisfaction.</p>
</section>
<section id="dataset-description" class="level4">
<h4 class="anchored" data-anchor-id="dataset-description">Dataset Description</h4>
<p>The dataset used in this analysis comprises survey responses from customers regarding their experiences and satisfaction with different payment cards. The survey includes questions about various features of the cards, such as trustworthiness, ease of use, rewards, and customer service. Each response is associated with several variables representing these features, along with an overall satisfaction score.</p>
</section>
<section id="objective" class="level4">
<h4 class="anchored" data-anchor-id="objective">Objective</h4>
<p>The primary objective of this article is to explore and compare different methods for calculating the importance of various features (variables) in determining customer satisfaction. Understanding which features most significantly impact satisfaction can provide valuable insights for businesses aiming to improve their payment card products and services. The methods explored in this analysis include Pearson correlations, standardized regression coefficients, Shapley values, permutation importance, Johnson’s relative weights, mean decrease in Gini coefficient, and XGBoost feature importance.</p>
</section>
</section>
<section id="data-description" class="level3">
<h3 class="anchored" data-anchor-id="data-description">2. Data Description</h3>
<section id="source-of-data" class="level4">
<h4 class="anchored" data-anchor-id="source-of-data">Source of Data</h4>
<p>The survey data was provided by Professor Dan Yavorsky at the University of California, San Diego (UCSD) as part of a school-related project.</p>
</section>
<section id="key-variables" class="level4">
<h4 class="anchored" data-anchor-id="key-variables">Key Variables</h4>
<p>The dataset includes several key variables that represent different aspects of payment cards, as reported by survey respondents. These variables include:</p>
<ul>
<li><strong>trust</strong>: Indicates whether the card is offered by a trusted brand.</li>
<li><strong>build</strong>: Represents how well the card helps build credit quickly.</li>
<li><strong>differs</strong>: Measures the uniqueness of the card compared to others.</li>
<li><strong>easy</strong>: Assesses the ease of use of the card.</li>
<li><strong>appealing</strong>: Reflects the appeal of the card’s benefits or rewards.</li>
<li><strong>rewarding</strong>: Captures the extent to which the card rewards responsible usage.</li>
<li><strong>popular</strong>: Indicates how commonly the card is used by others.</li>
<li><strong>service</strong>: Evaluates the quality of customer service provided.</li>
<li><strong>impact</strong>: Measures the overall impact the card has on the user’s life.</li>
</ul>
<p>Each variable is a binary or categorical representation of the survey responses, along with an overall satisfaction score for each respondent.</p>
</section>
<section id="data-sample" class="level4">
<h4 class="anchored" data-anchor-id="data-sample">Data Sample</h4>
<p>To give a snapshot of the dataset, below is an interactive dataset:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Survey Data
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="d9d4875b" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div>
<style>.itables table td {
    text-overflow: ellipsis;
    overflow: hidden;
}

.itables table th {
    text-overflow: ellipsis;
    overflow: hidden;
}

.itables thead input {
    width: 100%;
    padding: 3px;
    box-sizing: border-box;
}

.itables tfoot input {
    width: 100%;
    padding: 3px;
    box-sizing: border-box;
}
</style>
<div class="itables">

<table id="5e2f4ffc-1d60-42a4-9cad-c97fb1b50882" class="display nowrap table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th">brand</th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">satisfaction</th>
<th data-quarto-table-cell-role="th">trust</th>
<th data-quarto-table-cell-role="th">build</th>
<th data-quarto-table-cell-role="th">differs</th>
<th data-quarto-table-cell-role="th">easy</th>
<th data-quarto-table-cell-role="th">appealing</th>
<th data-quarto-table-cell-role="th">rewarding</th>
<th data-quarto-table-cell-role="th">popular</th>
<th data-quarto-table-cell-role="th">service</th>
<th data-quarto-table-cell-role="th">impact</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Loading... (need <a href="https://mwouts.github.io/itables/troubleshooting.html">help</a>?)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/1.13.1/css/jquery.dataTables.min.css">
<script type="module">
    // Import jquery and DataTable
    import 'https://code.jquery.com/jquery-3.6.0.min.js';
    import dt from 'https://cdn.datatables.net/1.12.1/js/jquery.dataTables.mjs';
    dt($);

    // Define the table data
    const data = [[1, 98, 3, 1, 0, 1, 1, 1, 0, 0, 1, 0], [1, 179, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 197, 3, 1, 0, 0, 1, 1, 1, 0, 1, 1], [1, 317, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1], [1, 356, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 395, 4, 1, 1, 0, 1, 1, 0, 1, 1, 0], [1, 586, 3, 1, 1, 1, 1, 1, 0, 1, 1, 0], [1, 596, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1], [1, 978, 3, 1, 0, 0, 0, 0, 0, 1, 0, 0], [1, 987, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1002, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1039, 2, 0, 0, 1, 1, 0, 0, 0, 0, 1], [1, 1087, 4, 1, 0, 0, 1, 1, 0, 1, 0, 0], [1, 1226, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1282, 3, 1, 1, 0, 1, 0, 0, 0, 1, 0], [1, 1548, 4, 1, 0, 1, 1, 0, 0, 1, 1, 1], [1, 1594, 4, 1, 0, 1, 1, 1, 1, 1, 0, 1], [1, 1637, 3, 1, 0, 0, 1, 1, 0, 0, 1, 0], [1, 1739, 5, 0, 0, 0, 0, 1, 1, 0, 0, 0], [1, 1796, 4, 1, 1, 1, 0, 0, 0, 0, 1, 0], [1, 1822, 4, 0, 0, 1, 0, 1, 0, 0, 1, 0], [1, 1856, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1871, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2055, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2111, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 2133, 4, 1, 0, 1, 1, 1, 0, 1, 1, 0], [1, 2154, 4, 0, 0, 0, 1, 1, 0, 1, 0, 1], [1, 2241, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 2273, 4, 1, 0, 0, 0, 0, 1, 0, 1, 0], [1, 2295, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 2297, 3, 0, 0, 0, 1, 0, 0, 1, 0, 0], [1, 2298, 4, 1, 0, 0, 1, 0, 0, 1, 0, 1], [1, 2434, 4, 1, 0, 0, 1, 1, 1, 1, 1, 1], [1, 2527, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 2586, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2605, 3, 1, 1, 1, 1, 1, 0, 1, 1, 1], [1, 2970, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 2993, 3, 1, 1, 0, 1, 1, 1, 0, 1, 1], [1, 3103, 4, 1, 0, 0, 0, 1, 0, 1, 1, 1], [1, 3154, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 3166, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 3233, 4, 1, 1, 0, 1, 0, 1, 1, 1, 1], [1, 3447, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 3671, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0], [1, 3686, 3, 1, 1, 1, 1, 1, 0, 0, 1, 0], [1, 3707, 4, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 3784, 4, 0, 0, 1, 1, 1, 0, 0, 0, 0], [1, 3825, 4, 1, 0, 1, 1, 1, 0, 0, 1, 0], [1, 3838, 4, 1, 1, 0, 1, 1, 1, 1, 0, 0], [1, 3907, 4, 1, 0, 0, 1, 0, 0, 0, 0, 0], [1, 3918, 5, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 3948, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 4026, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 4117, 4, 1, 0, 0, 0, 1, 1, 1, 0, 0], [1, 4286, 4, 1, 0, 0, 1, 1, 0, 1, 0, 0], [1, 4317, 2, 1, 0, 1, 0, 1, 0, 1, 0, 0], [1, 4404, 5, 1, 0, 0, 0, 1, 1, 1, 1, 0], [1, 4746, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 4844, 3, 0, 1, 0, 1, 0, 1, 0, 1, 0], [1, 4942, 5, 0, 1, 0, 1, 1, 0, 1, 1, 1], [1, 4973, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 5098, 5, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 5152, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0], [1, 5227, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 5237, 4, 0, 0, 0, 1, 0, 0, 0, 1, 0], [1, 5279, 5, 1, 1, 0, 1, 1, 1, 0, 1, 0], [1, 5612, 4, 1, 0, 0, 1, 1, 0, 0, 1, 0], [1, 5745, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1], [1, 5790, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 5793, 4, 1, 0, 1, 1, 0, 0, 1, 1, 1], [1, 5811, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 5854, 3, 0, 0, 0, 0, 1, 0, 0, 1, 0], [1, 5857, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 5876, 2, 0, 1, 1, 1, 1, 1, 0, 0, 0], [1, 5927, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 5970, 4, 0, 1, 1, 1, 1, 0, 1, 0, 1], [1, 6036, 4, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 6041, 4, 0, 0, 0, 1, 1, 0, 1, 0, 1], [1, 6071, 4, 1, 1, 0, 1, 1, 1, 1, 0, 0], [1, 6073, 4, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 6102, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 6157, 4, 1, 0, 1, 1, 0, 0, 0, 0, 0], [1, 6255, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 6307, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 6309, 4, 1, 0, 1, 0, 1, 1, 0, 0, 1], [1, 6319, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 6473, 3, 1, 1, 0, 1, 1, 0, 0, 1, 0], [1, 6477, 3, 1, 0, 0, 1, 1, 0, 1, 1, 1], [1, 6581, 3, 1, 0, 0, 1, 0, 1, 1, 0, 0], [1, 6621, 4, 1, 0, 1, 1, 1, 1, 1, 1, 0], [1, 6622, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 6630, 4, 1, 0, 1, 1, 1, 1, 0, 1, 1], [1, 6636, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 6860, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 6976, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1], [1, 7166, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 7221, 4, 1, 0, 1, 0, 0, 0, 0, 1, 1], [1, 7285, 4, 1, 1, 1, 1, 1, 1, 0, 1, 1], [1, 7450, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 7466, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 7526, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 7537, 5, 1, 0, 0, 0, 1, 1, 1, 0, 0], [1, 7638, 5, 1, 1, 1, 1, 1, 1, 0, 1, 1], [1, 7665, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 7711, 4, 1, 0, 0, 0, 0, 1, 1, 1, 0], [1, 7730, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 7734, 5, 0, 1, 0, 1, 0, 1, 0, 0, 0], [1, 7751, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 7837, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0], [1, 7857, 5, 1, 0, 0, 1, 1, 1, 1, 1, 0], [1, 8109, 3, 0, 1, 0, 0, 0, 1, 1, 0, 0], [1, 8145, 5, 1, 1, 1, 1, 1, 0, 1, 1, 1], [1, 8220, 5, 1, 0, 1, 0, 0, 1, 0, 0, 1], [1, 8252, 4, 1, 1, 0, 1, 1, 1, 1, 1, 0], [1, 8311, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 8349, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 8366, 4, 1, 1, 1, 1, 0, 0, 1, 1, 1], [1, 8407, 5, 1, 1, 1, 0, 1, 0, 1, 1, 1], [1, 8418, 4, 0, 0, 0, 1, 1, 0, 0, 0, 0], [1, 8461, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 8538, 5, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 8667, 4, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 8721, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 8726, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 8728, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 8806, 4, 1, 0, 0, 1, 0, 1, 1, 1, 1], [1, 8878, 3, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 8909, 4, 1, 0, 0, 1, 0, 0, 1, 1, 0], [1, 8913, 4, 1, 0, 0, 0, 0, 0, 0, 1, 0], [1, 8937, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 8995, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 9099, 5, 1, 0, 1, 1, 0, 1, 1, 1, 1], [1, 9197, 5, 0, 0, 0, 1, 1, 1, 1, 1, 0], [1, 9251, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 9320, 3, 0, 0, 0, 1, 1, 1, 1, 1, 0], [1, 9340, 2, 1, 0, 0, 1, 1, 0, 0, 1, 0], [1, 9347, 3, 1, 1, 1, 0, 1, 1, 1, 1, 0], [1, 9383, 4, 0, 0, 0, 1, 1, 1, 1, 1, 0], [1, 9451, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 9627, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 9689, 4, 1, 0, 1, 1, 1, 0, 0, 1, 1], [1, 9740, 4, 0, 0, 0, 0, 1, 0, 1, 0, 0], [1, 9845, 3, 1, 1, 0, 1, 0, 0, 0, 1, 0], [1, 9874, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 9931, 4, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 9943, 3, 0, 1, 1, 1, 0, 0, 0, 1, 0], [1, 9977, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0], [1, 10020, 5, 1, 1, 0, 1, 0, 1, 0, 1, 1], [1, 10189, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 10223, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 10243, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0], [1, 10343, 5, 1, 1, 1, 1, 1, 0, 1, 1, 1], [1, 10459, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 10519, 4, 1, 0, 0, 0, 1, 1, 0, 0, 0], [1, 10537, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 10561, 4, 1, 0, 0, 1, 0, 0, 0, 0, 0], [1, 10624, 4, 1, 1, 0, 1, 1, 0, 1, 0, 1], [1, 10631, 4, 1, 0, 0, 1, 0, 0, 1, 1, 0], [1, 10654, 4, 1, 0, 0, 1, 0, 0, 0, 1, 1], [1, 10665, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 10706, 3, 1, 0, 1, 1, 1, 1, 1, 0, 1], [1, 10710, 5, 0, 0, 1, 1, 1, 1, 1, 1, 1], [1, 10724, 2, 1, 0, 0, 1, 0, 0, 0, 1, 1], [1, 10769, 4, 0, 1, 0, 0, 0, 1, 0, 0, 0], [1, 10773, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1], [1, 10918, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 11006, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 11016, 3, 1, 0, 0, 0, 0, 0, 0, 1, 1], [1, 11039, 5, 1, 0, 1, 1, 1, 1, 0, 1, 1], [1, 11364, 5, 1, 0, 0, 1, 1, 0, 1, 0, 0], [1, 11378, 3, 0, 0, 1, 0, 0, 0, 0, 1, 0], [1, 11385, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 11404, 4, 1, 0, 1, 0, 1, 0, 1, 1, 0], [1, 11513, 3, 1, 1, 0, 1, 0, 0, 0, 0, 0], [1, 11621, 4, 1, 0, 0, 0, 1, 0, 0, 0, 0], [1, 11669, 4, 0, 0, 1, 0, 0, 0, 0, 0, 1], [1, 11670, 5, 1, 1, 0, 1, 0, 1, 1, 1, 0], [1, 11703, 5, 0, 0, 0, 1, 1, 0, 1, 0, 0], [1, 11888, 4, 1, 0, 1, 1, 1, 1, 1, 1, 0], [1, 12167, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 12365, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 12431, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 12521, 4, 1, 1, 1, 0, 1, 1, 1, 0, 0], [1, 12786, 4, 0, 0, 1, 1, 1, 1, 1, 0, 0], [1, 12987, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 13008, 4, 0, 0, 0, 1, 1, 1, 0, 0, 0], [1, 13052, 5, 1, 0, 0, 1, 1, 1, 1, 1, 0], [1, 13198, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 13214, 5, 1, 1, 0, 0, 1, 1, 1, 0, 0], [1, 13216, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 13329, 5, 1, 1, 1, 1, 1, 0, 0, 1, 0], [1, 13389, 4, 1, 0, 1, 1, 1, 1, 0, 0, 1], [1, 13496, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13699, 3, 1, 0, 1, 1, 1, 0, 1, 1, 1], [1, 13735, 3, 0, 1, 0, 1, 1, 1, 0, 0, 1], [1, 13741, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 13909, 5, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 14008, 5, 1, 1, 1, 1, 0, 0, 1, 1, 1], [1, 14019, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 14059, 4, 1, 0, 0, 0, 0, 1, 0, 1, 1], [1, 14153, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 14188, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 14197, 4, 1, 1, 1, 0, 1, 1, 0, 1, 0], [1, 14210, 2, 1, 0, 0, 1, 0, 0, 1, 0, 0], [1, 14420, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 14448, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0], [1, 14488, 5, 1, 1, 0, 1, 0, 1, 1, 1, 0], [1, 14590, 4, 1, 0, 0, 0, 0, 1, 1, 1, 0], [1, 14770, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 14800, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1], [1, 15054, 3, 1, 1, 0, 1, 1, 1, 1, 1, 1], [1, 15119, 5, 0, 1, 0, 1, 1, 0, 1, 1, 1], [1, 15126, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 15135, 3, 0, 0, 1, 1, 1, 1, 1, 1, 0], [1, 15170, 4, 1, 0, 0, 1, 1, 0, 1, 1, 0], [1, 15238, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 15389, 4, 1, 1, 0, 1, 1, 1, 0, 0, 1], [1, 15478, 4, 0, 1, 0, 0, 0, 0, 1, 1, 1], [1, 15487, 5, 1, 1, 0, 1, 1, 1, 1, 1, 1], [1, 15570, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 15615, 4, 1, 1, 1, 1, 1, 0, 1, 1, 1], [1, 15772, 4, 1, 0, 1, 1, 1, 1, 0, 1, 1], [1, 15803, 4, 0, 0, 1, 0, 0, 1, 0, 1, 0], [1, 15830, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 15867, 2, 1, 0, 1, 1, 1, 0, 0, 1, 0], [1, 15914, 4, 0, 0, 1, 0, 1, 1, 0, 0, 1], [1, 15926, 4, 0, 0, 0, 1, 1, 1, 0, 1, 1], [1, 15933, 5, 0, 1, 0, 0, 1, 0, 1, 1, 1], [1, 15936, 4, 0, 1, 1, 1, 1, 1, 1, 1, 0], [1, 15948, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 16012, 4, 1, 1, 0, 1, 1, 1, 1, 1, 1], [1, 16081, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 16088, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 16120, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 16148, 5, 1, 0, 1, 1, 0, 0, 1, 0, 0], [1, 16149, 5, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 16171, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 16206, 4, 1, 0, 0, 1, 1, 0, 0, 1, 0], [1, 16257, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 16307, 4, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 16461, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0], [1, 16508, 4, 1, 0, 0, 1, 0, 0, 1, 1, 1], [1, 16516, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 16602, 4, 1, 0, 0, 1, 0, 0, 1, 1, 1], [1, 16730, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0], [1, 16820, 4, 1, 0, 1, 1, 1, 1, 1, 0, 1], [1, 16981, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 16983, 3, 1, 0, 0, 0, 0, 1, 1, 1, 0], [1, 17022, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 17047, 2, 0, 0, 1, 1, 1, 0, 1, 0, 0], [1, 17205, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 17217, 4, 1, 1, 0, 1, 1, 0, 1, 1, 1], [1, 17220, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 17303, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 17385, 4, 1, 0, 0, 0, 0, 0, 1, 0, 0], [1, 17410, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 17431, 5, 1, 0, 1, 1, 1, 1, 1, 0, 1], [1, 17441, 2, 1, 1, 0, 1, 0, 1, 0, 1, 0], [1, 17625, 3, 1, 1, 1, 1, 1, 0, 1, 1, 1], [1, 17629, 4, 1, 1, 1, 1, 1, 0, 1, 1, 1], [1, 17730, 4, 1, 1, 0, 1, 1, 1, 0, 1, 0], [1, 17945, 4, 0, 1, 0, 1, 1, 1, 1, 1, 0], [1, 17954, 4, 1, 0, 0, 1, 1, 1, 0, 1, 1], [1, 18073, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0], [2, 179, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 309, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 356, 3, 1, 0, 0, 1, 1, 0, 1, 0, 0], [2, 364, 4, 1, 0, 0, 1, 1, 1, 1, 1, 1], [2, 369, 4, 0, 1, 0, 1, 0, 1, 1, 0, 1], [2, 391, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1], [2, 397, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0], [2, 474, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 520, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1], [2, 596, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [2, 648, 3, 1, 1, 0, 1, 0, 1, 0, 1, 1], [2, 860, 3, 1, 1, 0, 1, 1, 1, 1, 1, 0], [2, 914, 4, 0, 1, 1, 1, 0, 1, 0, 1, 0], [2, 987, 3, 1, 1, 1, 0, 1, 1, 1, 1, 1], [2, 1113, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0], [2, 1237, 4, 1, 1, 0, 1, 1, 1, 1, 1, 1], [2, 1294, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 1551, 3, 0, 0, 0, 0, 0, 0, 1, 0, 1], [2, 1594, 5, 1, 1, 0, 0, 0, 0, 0, 0, 1], [2, 1719, 3, 1, 0, 0, 1, 0, 0, 1, 0, 1], [2, 1730, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0], [2, 1736, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 1739, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0], [2, 1795, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 1796, 5, 1, 1, 0, 0, 0, 1, 0, 1, 0], [2, 1836, 5, 1, 0, 0, 1, 0, 0, 1, 1, 0], [2, 1871, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 1987, 3, 1, 1, 0, 1, 0, 0, 1, 0, 0], [2, 2111, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2133, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2154, 5, 1, 0, 0, 0, 0, 0, 1, 0, 0], [2, 2186, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2240, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2272, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0], [2, 2298, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0], [2, 2339, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0], [2, 2434, 4, 1, 0, 0, 1, 0, 0, 1, 0, 0], [2, 2443, 4, 0, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2527, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2535, 5, 1, 0, 0, 0, 0, 0, 1, 0, 0], [2, 2584, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2605, 3, 1, 1, 1, 1, 0, 1, 0, 1, 1], [2, 2733, 5, 1, 0, 1, 1, 1, 0, 1, 0, 0], [2, 2894, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2910, 5, 1, 1, 0, 1, 1, 1, 1, 0, 1], [2, 2968, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2970, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 3103, 4, 1, 0, 0, 0, 1, 0, 1, 1, 1], [2, 3233, 4, 1, 1, 1, 1, 0, 1, 0, 1, 1], [2, 3290, 3, 0, 0, 0, 0, 1, 1, 0, 0, 0], [2, 3316, 4, 1, 1, 0, 1, 1, 1, 1, 1, 1], [2, 3343, 3, 1, 0, 0, 0, 1, 1, 1, 1, 0], [2, 3431, 4, 1, 1, 0, 0, 0, 1, 1, 0, 1], [2, 3447, 5, 0, 1, 0, 0, 0, 1, 0, 0, 1], [2, 3564, 3, 0, 0, 0, 0, 0, 0, 1, 1, 0], [2, 3607, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 3784, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 3842, 2, 1, 0, 0, 1, 1, 0, 0, 1, 0], [2, 3852, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1], [2, 3892, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 3907, 4, 1, 0, 1, 0, 0, 0, 0, 0, 0], [2, 3918, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 3965, 3, 1, 1, 0, 1, 1, 1, 1, 1, 0], [2, 3978, 3, 0, 1, 0, 1, 0, 0, 1, 1, 0], [2, 3993, 4, 1, 0, 1, 1, 1, 1, 0, 1, 0], [2, 4066, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], [2, 4093, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 4735, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 4746, 5, 0, 0, 0, 0, 1, 0, 0, 1, 1], [2, 4806, 3, 1, 0, 0, 1, 1, 1, 1, 0, 1], [2, 4973, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5090, 4, 1, 0, 0, 0, 1, 1, 0, 0, 0], [2, 5215, 4, 1, 1, 1, 1, 0, 1, 1, 1, 0], [2, 5262, 4, 0, 0, 0, 1, 1, 0, 1, 1, 0], [2, 5358, 3, 1, 0, 1, 1, 1, 1, 1, 0, 0], [2, 5378, 3, 0, 0, 0, 0, 1, 1, 1, 1, 0], [2, 5437, 5, 0, 0, 0, 0, 1, 0, 0, 0, 1], [9, 13817, 4, 0, 0, 0, 0, 1, 0, 0, 0, 0], [9, 13887, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0], [9, 13907, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0], [9, 14008, 2, 1, 1, 1, 1, 0, 0, 1, 1, 0], [9, 14019, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 14059, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 14140, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9, 14248, 3, 1, 0, 0, 0, 0, 0, 1, 0, 0], [9, 14301, 3, 0, 1, 0, 0, 1, 1, 0, 0, 0], [9, 14420, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 14448, 4, 1, 1, 0, 1, 0, 1, 1, 1, 0], [9, 14465, 4, 0, 1, 1, 1, 1, 0, 1, 0, 0], [9, 14552, 4, 0, 1, 0, 0, 1, 1, 0, 0, 0], [9, 14818, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0], [9, 14870, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9, 14968, 5, 1, 1, 0, 1, 1, 1, 1, 1, 1], [9, 15008, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9, 15023, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 15170, 2, 1, 0, 0, 0, 1, 0, 0, 1, 0], [9, 15238, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 15385, 4, 1, 1, 1, 0, 0, 0, 1, 0, 0], [9, 15421, 5, 1, 1, 1, 1, 1, 1, 1, 0, 1], [9, 15458, 5, 0, 1, 1, 0, 0, 0, 1, 1, 0], [9, 15462, 2, 1, 0, 0, 0, 0, 1, 0, 1, 0], [9, 15478, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0], [9, 15570, 3, 1, 0, 0, 0, 0, 0, 1, 0, 0], [9, 15607, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1], [9, 15673, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9, 15697, 4, 0, 1, 0, 0, 0, 0, 1, 0, 0], [9, 15772, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 15790, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 15803, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0], [9, 15922, 4, 0, 0, 1, 1, 0, 0, 0, 1, 1], [9, 16077, 4, 1, 1, 1, 0, 1, 0, 1, 1, 0], [9, 16088, 5, 0, 0, 0, 1, 0, 0, 1, 0, 0], [9, 16148, 4, 1, 1, 0, 1, 1, 1, 1, 0, 0], [9, 16149, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 16206, 3, 1, 1, 0, 1, 1, 0, 1, 1, 1], [9, 16255, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0], [9, 16257, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0], [9, 16286, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1], [9, 16437, 4, 1, 0, 0, 0, 0, 0, 0, 1, 0], [9, 16730, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0], [9, 16761, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0], [9, 16763, 5, 1, 0, 0, 0, 0, 0, 1, 1, 0], [9, 16820, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9, 16828, 4, 1, 1, 0, 0, 0, 1, 1, 0, 0], [9, 16922, 4, 1, 1, 0, 0, 0, 0, 0, 0, 0], [9, 17022, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 17047, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], [9, 17156, 3, 0, 0, 0, 1, 1, 1, 1, 0, 0], [9, 17348, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 17358, 2, 0, 1, 0, 0, 1, 0, 1, 1, 0], [9, 17410, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 17730, 4, 1, 1, 0, 1, 0, 0, 0, 1, 0], [9, 17800, 2, 0, 1, 1, 0, 0, 1, 0, 1, 1], [9, 17808, 3, 1, 0, 0, 1, 0, 1, 1, 1, 0], [9, 17811, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 17984, 3, 1, 1, 0, 1, 0, 1, 0, 0, 0], [9, 18073, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 158, 3, 1, 1, 0, 0, 0, 0, 1, 0, 0], [10, 179, 5, 1, 0, 1, 0, 0, 1, 1, 0, 0], [10, 197, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0], [10, 309, 2, 1, 1, 0, 1, 0, 1, 0, 1, 0], [10, 391, 5, 0, 1, 0, 0, 0, 0, 0, 0, 0], [10, 395, 2, 1, 1, 0, 1, 1, 0, 1, 1, 0], [10, 520, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 586, 3, 1, 1, 0, 0, 0, 0, 0, 1, 0], [10, 596, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 600, 4, 1, 1, 1, 1, 1, 0, 1, 1, 1], [10, 781, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0], [10, 896, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], [10, 914, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 968, 4, 1, 1, 0, 1, 0, 0, 1, 1, 0], [10, 1002, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 1041, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 1087, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0], [10, 1237, 4, 1, 1, 0, 1, 1, 1, 1, 1, 1], [10, 1282, 3, 1, 1, 1, 1, 1, 0, 0, 1, 0], [10, 1294, 4, 1, 0, 0, 1, 0, 1, 1, 1, 1], [10, 1550, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 1585, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 1594, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1], [10, 1701, 4, 0, 1, 1, 1, 1, 0, 1, 0, 0], [10, 1719, 3, 1, 0, 1, 0, 1, 1, 1, 1, 0], [10, 1758, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0], [10, 1788, 5, 0, 1, 1, 0, 0, 0, 0, 0, 0], [10, 1796, 5, 1, 1, 0, 0, 0, 1, 1, 1, 0], [10, 1813, 5, 1, 1, 1, 1, 1, 1, 1, 1, 0], [10, 1856, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0], [10, 1860, 5, 1, 1, 1, 1, 1, 1, 1, 1, 0], [10, 1938, 2, 0, 0, 0, 1, 0, 0, 1, 1, 0], [10, 1987, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0], [10, 2012, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 2111, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 2193, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 2200, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0], [10, 2240, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 2241, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0], [10, 2272, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0], [10, 2295, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 2434, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0], [10, 2437, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 2443, 4, 0, 1, 1, 1, 1, 0, 1, 0, 1], [10, 2531, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 2535, 5, 1, 0, 0, 0, 0, 0, 1, 0, 0], [10, 2657, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0], [10, 2779, 5, 1, 0, 1, 0, 0, 0, 0, 0, 0], [10, 2910, 5, 1, 1, 0, 1, 1, 1, 1, 1, 1], [10, 2967, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 2968, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 2993, 3, 1, 1, 0, 1, 1, 1, 0, 1, 1], [10, 3042, 4, 1, 1, 1, 1, 0, 1, 0, 1, 0], [10, 3107, 5, 1, 1, 0, 1, 0, 1, 0, 1, 0], [10, 3125, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 3166, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 3186, 4, 1, 1, 0, 1, 0, 1, 1, 1, 0], [10, 3187, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1], [10, 3291, 3, 1, 0, 0, 0, 1, 1, 0, 1, 0], [10, 3329, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0], [10, 3343, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 3431, 4, 1, 0, 0, 1, 1, 1, 0, 1, 1], [10, 3447, 5, 0, 0, 0, 1, 0, 0, 0, 0, 0], [10, 3489, 4, 1, 0, 0, 0, 0, 0, 1, 1, 1], [10, 3607, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0], [10, 3654, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 3665, 4, 1, 0, 1, 0, 1, 0, 1, 1, 0], [10, 3707, 4, 0, 1, 0, 1, 0, 0, 0, 0, 1], [10, 3727, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 3778, 4, 1, 0, 0, 1, 0, 0, 0, 1, 0], [10, 3811, 4, 1, 0, 0, 1, 1, 0, 1, 1, 0], [10, 3838, 2, 1, 0, 0, 0, 0, 1, 1, 1, 0], [10, 3842, 4, 1, 0, 0, 0, 1, 0, 1, 1, 0], [10, 3892, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 3918, 4, 0, 1, 1, 0, 0, 0, 0, 1, 0], [10, 3959, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0], [10, 3965, 4, 1, 1, 0, 1, 1, 1, 1, 1, 0], [10, 3978, 4, 1, 1, 1, 1, 1, 0, 1, 1, 0], [10, 3993, 4, 1, 1, 0, 1, 0, 1, 0, 1, 1], [10, 4117, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0], [10, 4223, 3, 0, 0, 0, 1, 0, 0, 0, 1, 0], [10, 4425, 3, 1, 1, 0, 1, 1, 1, 0, 1, 0], [10, 4508, 5, 1, 1, 0, 1, 1, 1, 0, 0, 0], [10, 4558, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], [10, 4806, 3, 1, 0, 0, 1, 1, 1, 1, 1, 1], [10, 4894, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 4909, 5, 1, 0, 0, 1, 1, 1, 1, 1, 0], [10, 4988, 4, 0, 0, 1, 0, 1, 0, 0, 0, 0], [10, 5378, 3, 1, 0, 1, 0, 0, 0, 0, 1, 0], [10, 5462, 4, 1, 1, 0, 1, 1, 1, 1, 1, 0], [10, 5790, 4, 0, 0, 1, 1, 1, 0, 1, 1, 1], [10, 5793, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 5810, 3, 1, 0, 0, 1, 0, 0, 0, 0, 0], [10, 5854, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0], [10, 5876, 4, 1, 0, 0, 1, 0, 0, 1, 0, 1], [10, 5888, 4, 0, 0, 0, 0, 0, 0, 1, 1, 0], [10, 5927, 5, 0, 0, 0, 0, 1, 1, 1, 1, 1], [10, 5970, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0], [10, 5973, 4, 1, 0, 0, 0, 1, 0, 0, 1, 1], [10, 5974, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 5999, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 6073, 3, 1, 1, 1, 0, 0, 1, 0, 1, 0], [10, 6174, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 6232, 4, 1, 1, 0, 1, 1, 0, 1, 0, 0], [10, 6277, 3, 1, 1, 0, 0, 1, 0, 1, 0, 0], [10, 6287, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 6370, 4, 1, 1, 1, 1, 1, 0, 1, 1, 1], [10, 6431, 4, 1, 0, 0, 0, 1, 0, 1, 0, 0], [10, 6496, 4, 0, 1, 1, 1, 0, 0, 1, 0, 0], [10, 6581, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 6630, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 6670, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 6730, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 6841, 3, 0, 0, 0, 1, 1, 0, 0, 0, 0], [10, 6989, 3, 1, 1, 1, 1, 1, 0, 1, 1, 1], [10, 7207, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 7285, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 7311, 4, 1, 0, 0, 0, 0, 0, 0, 1, 0], [10, 7410, 3, 1, 1, 1, 0, 1, 0, 1, 0, 0], [10, 7444, 4, 0, 0, 1, 0, 0, 0, 0, 0, 0], [10, 7526, 4, 1, 1, 1, 1, 0, 0, 1, 1, 1], [10, 7646, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 7658, 4, 1, 0, 1, 0, 1, 0, 1, 0, 0], [10, 7665, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 7730, 4, 1, 0, 1, 0, 0, 1, 1, 1, 0], [10, 7774, 3, 1, 0, 0, 1, 0, 0, 0, 1, 1], [10, 7805, 3, 0, 1, 0, 0, 0, 0, 0, 1, 0], [10, 7909, 5, 1, 1, 0, 1, 0, 0, 0, 1, 0], [10, 8109, 4, 0, 1, 1, 1, 1, 1, 0, 0, 0], [10, 8145, 5, 1, 1, 1, 0, 1, 0, 1, 0, 1], [10, 8171, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 8177, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 8245, 5, 0, 0, 0, 1, 0, 0, 0, 0, 0], [10, 8331, 5, 0, 1, 1, 0, 1, 1, 1, 1, 1], [10, 8461, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 8467, 3, 1, 1, 0, 1, 0, 0, 1, 0, 0], [10, 8656, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 8667, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 8721, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 8790, 5, 1, 1, 0, 1, 0, 0, 0, 1, 0], [10, 8806, 3, 1, 0, 1, 0, 1, 0, 0, 0, 1], [10, 8878, 3, 1, 1, 0, 1, 0, 1, 0, 0, 0], [10, 8909, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0], [10, 8967, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 9050, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 9099, 5, 1, 0, 0, 1, 0, 1, 1, 1, 1], [10, 9122, 3, 1, 1, 0, 1, 1, 1, 1, 1, 0], [10, 9171, 2, 1, 0, 0, 1, 1, 1, 1, 1, 0], [10, 9197, 2, 0, 0, 0, 0, 0, 1, 1, 1, 0], [10, 9212, 4, 0, 1, 0, 1, 0, 0, 1, 1, 1], [10, 9353, 4, 1, 0, 0, 0, 0, 0, 0, 1, 0], [10, 9434, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 9497, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 9616, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 9627, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 9638, 2, 1, 0, 0, 1, 1, 0, 0, 1, 0], [10, 9689, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 9759, 4, 1, 1, 0, 0, 0, 0, 1, 1, 1], [10, 9782, 4, 1, 1, 0, 1, 0, 1, 1, 1, 1], [10, 9833, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 9873, 4, 1, 1, 0, 1, 1, 1, 0, 0, 0], [10, 9874, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], [10, 9907, 3, 0, 0, 0, 1, 1, 0, 0, 0, 0], [10, 10020, 5, 1, 1, 0, 1, 1, 1, 1, 1, 1], [10, 10042, 3, 1, 0, 0, 1, 0, 1, 0, 0, 0], [10, 10069, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 10165, 3, 0, 0, 0, 0, 1, 1, 0, 1, 1], [10, 10176, 3, 1, 0, 0, 0, 1, 0, 0, 0, 0], [10, 10189, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0], [10, 10259, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 10374, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 10429, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0], [10, 10505, 5, 1, 0, 0, 1, 0, 1, 1, 1, 1], [10, 10537, 4, 1, 0, 0, 0, 0, 1, 1, 1, 1], [10, 10585, 3, 1, 1, 0, 1, 0, 0, 1, 1, 0], [10, 10631, 3, 1, 1, 0, 1, 1, 0, 1, 1, 0], [10, 10706, 3, 0, 1, 0, 1, 0, 1, 0, 1, 0], [10, 10779, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0], [10, 10843, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 10918, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 10935, 4, 1, 1, 0, 1, 0, 0, 0, 1, 1], [10, 10939, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0], [10, 11006, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 11178, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0], [10, 11198, 4, 1, 1, 0, 1, 0, 0, 1, 1, 1], [10, 11385, 5, 1, 0, 0, 1, 0, 0, 1, 0, 1], [10, 11461, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 11472, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [10, 11599, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 11621, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 11669, 2, 0, 0, 0, 0, 1, 1, 1, 0, 0], [10, 11670, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0], [10, 11703, 5, 1, 1, 0, 1, 0, 1, 1, 1, 0], [10, 11798, 4, 1, 1, 0, 0, 1, 1, 0, 1, 0], [10, 11874, 4, 1, 1, 0, 1, 1, 1, 1, 1, 0], [10, 11990, 3, 0, 0, 0, 0, 0, 1, 1, 0, 0], [10, 12156, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 12186, 3, 1, 1, 0, 0, 0, 0, 1, 1, 0], [10, 12190, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 12199, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 12364, 4, 1, 1, 0, 1, 1, 1, 1, 1, 1], [10, 12365, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 12431, 4, 0, 1, 0, 1, 0, 0, 1, 1, 0], [10, 12786, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0], [10, 12987, 5, 0, 0, 0, 0, 0, 1, 1, 1, 0], [10, 13043, 4, 1, 1, 0, 1, 0, 1, 1, 1, 1], [10, 13046, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 13091, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0], [10, 13221, 3, 1, 1, 1, 0, 1, 1, 1, 1, 1], [10, 13314, 5, 0, 0, 1, 0, 0, 0, 1, 1, 0], [10, 13340, 4, 1, 1, 0, 0, 0, 0, 1, 1, 0], [10, 13389, 4, 1, 0, 1, 1, 1, 1, 1, 0, 1], [10, 13431, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1], [10, 13496, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 13545, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 13631, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], [10, 13669, 3, 1, 1, 0, 1, 0, 1, 1, 1, 0], [10, 13715, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 13887, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 13907, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0], [10, 13959, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 13980, 3, 0, 1, 0, 1, 0, 0, 1, 0, 0], [10, 13997, 4, 1, 1, 0, 0, 0, 1, 0, 1, 1], [10, 14000, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 14008, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0], [10, 14018, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 14141, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0], [10, 14188, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 14391, 5, 1, 1, 0, 1, 0, 1, 1, 1, 1], [10, 14448, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0], [10, 14462, 4, 1, 0, 0, 0, 0, 1, 0, 1, 0], [10, 14488, 5, 1, 1, 0, 1, 0, 1, 1, 1, 0], [10, 14489, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], [10, 14547, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0], [10, 14616, 2, 1, 0, 0, 0, 1, 1, 0, 0, 0], [10, 14757, 4, 0, 1, 0, 1, 1, 1, 1, 1, 1], [10, 14786, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 14800, 5, 1, 1, 0, 1, 1, 0, 0, 1, 1], [10, 14818, 4, 1, 1, 0, 1, 1, 1, 1, 1, 1], [10, 14842, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 14968, 5, 1, 0, 0, 1, 1, 1, 1, 1, 0], [10, 15157, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 15380, 4, 1, 1, 0, 1, 1, 1, 0, 1, 0], [10, 15473, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 15478, 4, 0, 0, 1, 1, 1, 1, 0, 1, 1], [10, 15570, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 15645, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 15673, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 15722, 5, 1, 1, 0, 1, 1, 1, 1, 1, 0], [10, 15790, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 15916, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 15917, 4, 0, 0, 1, 0, 1, 1, 0, 1, 0], [10, 15948, 4, 1, 1, 1, 1, 0, 1, 0, 0, 0], [10, 16149, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 16255, 3, 1, 0, 0, 1, 1, 0, 0, 0, 0], [10, 16257, 3, 1, 1, 0, 0, 0, 0, 1, 1, 0], [10, 16348, 3, 0, 1, 0, 0, 0, 1, 0, 0, 1], [10, 16352, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 16381, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 16508, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 16602, 3, 1, 0, 0, 1, 0, 0, 1, 1, 0], [10, 16763, 5, 1, 0, 0, 0, 0, 0, 1, 0, 0], [10, 16818, 4, 0, 1, 1, 1, 1, 1, 0, 1, 1], [10, 16820, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 16837, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1], [10, 16892, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 16922, 4, 1, 1, 0, 0, 1, 0, 1, 0, 0], [10, 17047, 4, 0, 0, 1, 1, 0, 1, 0, 1, 0], [10, 17156, 2, 0, 0, 0, 0, 1, 1, 1, 0, 0], [10, 17205, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 17285, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 17348, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 17385, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0], [10, 17391, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], [10, 17410, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10, 17730, 4, 1, 1, 0, 1, 0, 0, 1, 0, 0], [10, 17800, 5, 1, 1, 0, 1, 0, 1, 1, 1, 1], [10, 17808, 3, 1, 0, 0, 1, 0, 1, 1, 1, 0], [10, 17893, 5, 0, 1, 1, 0, 0, 0, 0, 0, 0], [10, 17984, 3, 1, 1, 0, 1, 0, 1, 0, 0, 0], [10, 18073, 4, 0, 1, 0, 1, 0, 0, 0, 0, 0]];

    // Define the dt_args
    let dt_args = {"order": [], "fnInfoCallback": function (oSettings, iStart, iEnd, iMax, iTotal, sPre) { return sPre + ' (<a href="https://mwouts.github.io/itables/downsampling.html">downsampled</a> from 2,553x12 to 682x12 as maxBytes=65536)'; }};
    dt_args["data"] = data;

    $(document).ready(function () {
        
        $('#5e2f4ffc-1d60-42a4-9cad-c97fb1b50882').DataTable(dt_args);
    });
</script>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<ul>
<li><strong>Number of Rows</strong>: 2553</li>
<li><strong>Number of Columns</strong>: 12</li>
</ul>
</section>
</section>
<section id="methods-for-calculating-feature-importance" class="level3">
<h3 class="anchored" data-anchor-id="methods-for-calculating-feature-importance">3. Methods for Calculating Feature Importance</h3>
<section id="introduction-to-methods" class="level4">
<h4 class="anchored" data-anchor-id="introduction-to-methods">Introduction to Methods</h4>
<p>Understanding which features most significantly influence customer satisfaction is crucial for businesses aiming to enhance their payment card offerings. In this section, we explore various methods to calculate the importance of different features (variables) in determining overall satisfaction. Each method offers a unique perspective on feature importance, and by comparing them, we can gain a comprehensive understanding of the factors that matter most to customers.</p>
<p>The methods explored in this analysis include:</p>
<ul>
<li><strong>Pearson Correlations</strong>: Measures the linear relationship between each feature and customer satisfaction.</li>
<li><strong>Standardized Regression Coefficients</strong>: Provides insights from a linear regression model, indicating the relative contribution of each standardized feature to the prediction of satisfaction.</li>
<li><strong>Usefulness (Shapley Values)</strong>: Uses cooperative game theory to fairly distribute the “payout” (importance) among features.</li>
<li><strong>Usefulness (Permutation Importance)</strong>: Assesses the change in model performance when the values of a feature are randomly shuffled.</li>
<li><strong>Johnson’s Relative Weights</strong>: Decomposes the multiple correlation coefficient to determine the relative contribution of each predictor.</li>
<li><strong>Mean Decrease in Gini Coefficient</strong>: Measures feature importance in a Random Forest model based on the decrease in node impurity.</li>
<li><strong>XGBoost Feature Importance</strong>: Uses the XGBoost algorithm to calculate feature importance based on the gain in performance each feature provides.</li>
</ul>
<p>In the following subsections, we will delve into each method, describing how it works, how it was implemented in this analysis, and the results obtained.</p>
</section>
<section id="pearson-correlations" class="level4">
<h4 class="anchored" data-anchor-id="pearson-correlations">3.1 Pearson Correlations</h4>
<p><strong>Description</strong>: Pearson correlation is a statistical measure that calculates the strength and direction of the linear relationship between two variables. The Pearson correlation coefficient ranges from -1 to 1, where:</p>
<ul>
<li><p>1 indicates a perfect positive linear relationship,</p></li>
<li><p>-1 indicates a perfect negative linear relationship, and</p></li>
<li><p>0 indicates no linear relationship.</p></li>
</ul>
<p>In the context of this analysis, Pearson correlations help us understand how each feature (e.g., trust, ease of use) is related to overall customer satisfaction.</p>
<p><strong>Implementation</strong>: To calculate the Pearson correlations for this dataset, we used the <code>pandas</code> library in Python. Specifically, we computed the correlation between the <code>satisfaction</code> variable and each of the other features. The steps are as follows:</p>
<ol type="1">
<li><p>Load the dataset into a pandas DataFrame.</p></li>
<li><p>Use the <code>corr</code> method with the <code>pearson</code> argument to calculate the Pearson correlation coefficient between <code>satisfaction</code> and each feature.</p></li>
</ol>
<p>Here is a snippet of the code used:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">'data_for_drivers_analysis.csv'</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate Pearson correlations</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>pearson_correlations <span class="op">=</span> data.corr(method<span class="op">=</span><span class="st">'pearson'</span>)[<span class="st">'satisfaction'</span>].drop(<span class="st">'satisfaction'</span>).sort_index()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Results</strong>: The Pearson correlation coefficients for the features are as follows:</p>
<table class="table">
<thead>
<tr class="header">
<th>Feature</th>
<th>Pearson Correlation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>brand</td>
<td>-0.0493</td>
</tr>
<tr class="even">
<td>trust</td>
<td>0.2557</td>
</tr>
<tr class="odd">
<td>build</td>
<td>0.1919</td>
</tr>
<tr class="even">
<td>differs</td>
<td>0.1848</td>
</tr>
<tr class="odd">
<td>easy</td>
<td>0.2130</td>
</tr>
<tr class="even">
<td>appealing</td>
<td>0.2080</td>
</tr>
<tr class="odd">
<td>rewarding</td>
<td>0.1946</td>
</tr>
<tr class="even">
<td>popular</td>
<td>0.1714</td>
</tr>
<tr class="odd">
<td>service</td>
<td>0.2511</td>
</tr>
<tr class="even">
<td>impact</td>
<td>0.2545</td>
</tr>
</tbody>
</table>
<p>These results indicate that the features <code>trust</code>, <code>service</code>, and <code>impact</code> have the highest positive correlations with customer satisfaction. Conversely, the feature <code>brand</code> shows a slight negative correlation with satisfaction, indicating that it might not be a significant driver of satisfaction in this context.</p>
</section>
<section id="standardized-regression-coefficients" class="level4">
<h4 class="anchored" data-anchor-id="standardized-regression-coefficients">3.2 Standardized Regression Coefficients</h4>
<p><strong>Description</strong>: Standardized regression coefficients, also known as beta coefficients, are the coefficients obtained from a linear regression model when all variables have been standardized (i.e., converted to have a mean of 0 and a standard deviation of 1). These coefficients allow for the comparison of the relative importance of each predictor variable in the model. The higher the absolute value of the standardized coefficient, the greater the impact of that variable on the dependent variable (in this case, customer satisfaction).</p>
<p><strong>Implementation</strong>: To calculate standardized regression coefficients, we followed these steps:</p>
<ol type="1">
<li><p>Standardize all predictor variables and the dependent variable using the <code>StandardScaler</code> from the <code>sklearn.preprocessing</code> module.</p></li>
<li><p>Fit a linear regression model using the standardized variables.</p></li>
<li><p>Extract the coefficients from the model, which are the standardized regression coefficients.</p></li>
</ol>
<p>Here is a snippet of the code used:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize the features</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(data.drop(columns<span class="op">=</span>[<span class="st">'satisfaction'</span>, <span class="st">'id'</span>]))</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>y_scaled <span class="op">=</span> scaler.fit_transform(data[[<span class="st">'satisfaction'</span>]])</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the linear regression model</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>model.fit(X_scaled, y_scaled)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the standardized regression coefficients</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>standardized_coefficients <span class="op">=</span> pd.Series(model.coef_[<span class="dv">0</span>], index<span class="op">=</span>data.columns.drop([<span class="st">'satisfaction'</span>, <span class="st">'id'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Results</strong>: The standardized regression coefficients for the features are as follows:</p>
<table class="table">
<thead>
<tr class="header">
<th>Feature</th>
<th>Standardized Coefficient</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>brand</td>
<td>0.0121</td>
</tr>
<tr class="even">
<td>trust</td>
<td>0.1357</td>
</tr>
<tr class="odd">
<td>build</td>
<td>0.0228</td>
</tr>
<tr class="even">
<td>differs</td>
<td>0.0333</td>
</tr>
<tr class="odd">
<td>easy</td>
<td>0.0264</td>
</tr>
<tr class="even">
<td>appealing</td>
<td>0.0413</td>
</tr>
<tr class="odd">
<td>rewarding</td>
<td>0.0065</td>
</tr>
<tr class="even">
<td>popular</td>
<td>0.0203</td>
</tr>
<tr class="odd">
<td>service</td>
<td>0.1031</td>
</tr>
<tr class="even">
<td>impact</td>
<td>0.1508</td>
</tr>
</tbody>
</table>
<p>These results show that <code>impact</code>, <code>trust</code>, and <code>service</code> have the largest standardized regression coefficients, indicating that they have the greatest relative importance in predicting customer satisfaction. The feature <code>brand</code>, on the other hand, has the smallest coefficient, suggesting it has a minimal impact on satisfaction compared to the other features.</p>
</section>
<section id="usefulness-shapley-values" class="level4">
<h4 class="anchored" data-anchor-id="usefulness-shapley-values">3.3 Usefulness (Shapley Values)</h4>
<p><strong>Description</strong>: Shapley values, derived from cooperative game theory, are used to fairly distribute the “payout” (or importance) among players (or features) based on their contributions. In feature importance analysis, Shapley values quantify the contribution of each feature to the predictions made by a model. They are advantageous because they consider all possible combinations of features, providing a thorough assessment of each feature’s importance.</p>
<p><strong>Implementation</strong>: To calculate Shapley values for this dataset, we used the <code>shap</code> library in Python. The steps involved are:</p>
<ol type="1">
<li><p>Train a linear regression model using the dataset.</p></li>
<li><p>Use the <code>shap.Explainer</code> to calculate Shapley values for each feature in the model.</p></li>
<li><p>Compute the mean absolute Shapley values to determine the importance of each feature.</p></li>
</ol>
<p>Here is the code used:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shap</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Train a linear regression model for SHAP values</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>model_shap <span class="op">=</span> LinearRegression()</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>model_shap.fit(X, y)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate SHAP values</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>explainer <span class="op">=</span> shap.Explainer(model_shap, X)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>shap_values <span class="op">=</span> explainer(X)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the mean absolute Shapley values for each feature</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>shapley_values <span class="op">=</span> pd.Series(np.<span class="bu">abs</span>(shap_values.values).mean(axis<span class="op">=</span><span class="dv">0</span>), index<span class="op">=</span>X.columns)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the Shapley values</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>shapley_values.sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Results</strong>: The Shapley values for the features are as follows:</p>
<table class="table">
<thead>
<tr class="header">
<th>Feature</th>
<th>Shapley Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>trust</td>
<td>0.136622</td>
</tr>
<tr class="even">
<td>impact</td>
<td>0.130991</td>
</tr>
<tr class="odd">
<td>service</td>
<td>0.101534</td>
</tr>
<tr class="even">
<td>appealing</td>
<td>0.040723</td>
</tr>
<tr class="odd">
<td>differs</td>
<td>0.029423</td>
</tr>
<tr class="even">
<td>easy</td>
<td>0.026634</td>
</tr>
<tr class="odd">
<td>build</td>
<td>0.022562</td>
</tr>
<tr class="even">
<td>popular</td>
<td>0.020249</td>
</tr>
<tr class="odd">
<td>brand</td>
<td>0.010036</td>
</tr>
<tr class="even">
<td>rewarding</td>
<td>0.006399</td>
</tr>
</tbody>
</table>
<p>These results indicate that <code>trust</code>, <code>impact</code>, and <code>service</code> are the most influential features in determining customer satisfaction, as indicated by their high Shapley values. This finding is consistent with other methods used in the analysis, further emphasizing the importance of these features.</p>
</section>
<section id="usefulness-permutation-importance" class="level4">
<h4 class="anchored" data-anchor-id="usefulness-permutation-importance">3.4 Usefulness (Permutation Importance)</h4>
<p><strong>Description</strong>: Permutation importance is a model-agnostic method for estimating the importance of features. It involves randomly shuffling the values of each feature and observing the impact on the model’s performance. The idea is that if a feature is important, permuting its values should lead to a significant decrease in the model’s performance. This method is particularly useful in machine learning because it provides insights into the contribution of each feature without being tied to a specific model.</p>
<p><strong>Implementation</strong>: To calculate permutation importance for this dataset, we followed these steps:</p>
<ol type="1">
<li><p>Train a linear regression model using the dataset.</p></li>
<li><p>Apply the permutation importance method, which involves shuffling each feature’s values and measuring the change in the model’s performance.</p></li>
<li><p>Compute the mean decrease in performance for each feature, which represents its importance.</p></li>
</ol>
<p>Here is a snippet of the code used:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> permutation_importance</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the linear regression model</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>model.fit(X, y)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate permutation feature importance</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> permutation_importance(model, X, y, n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Series for the feature importances</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>permutation_importances <span class="op">=</span> pd.Series(result.importances_mean, index<span class="op">=</span>X.columns)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the permutation importances</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>permutation_importances.sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Results</strong>: The permutation importance values for the features are as follows:</p>
<table class="table">
<thead>
<tr class="header">
<th>Feature</th>
<th>Permutation Importance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>impact</td>
<td>0.033393</td>
</tr>
<tr class="even">
<td>trust</td>
<td>0.027346</td>
</tr>
<tr class="odd">
<td>service</td>
<td>0.016385</td>
</tr>
<tr class="even">
<td>appealing</td>
<td>0.002693</td>
</tr>
<tr class="odd">
<td>differs</td>
<td>0.001756</td>
</tr>
<tr class="even">
<td>easy</td>
<td>0.001021</td>
</tr>
<tr class="odd">
<td>build</td>
<td>0.000988</td>
</tr>
<tr class="even">
<td>popular</td>
<td>0.000474</td>
</tr>
<tr class="odd">
<td>brand</td>
<td>0.000438</td>
</tr>
<tr class="even">
<td>rewarding</td>
<td>0.000125</td>
</tr>
</tbody>
</table>
<p>These results indicate that <code>impact</code>, <code>trust</code>, and <code>service</code> have the highest permutation importance values, suggesting they are the most influential features in determining customer satisfaction. This aligns with the findings from the Shapley values and standardized regression coefficients, reinforcing the importance of these features.</p>
</section>
<section id="johnsons-relative-weights" class="level4">
<h4 class="anchored" data-anchor-id="johnsons-relative-weights">3.5 Johnson’s Relative Weights</h4>
<p><strong>Description</strong>: Johnson’s relative weights are used in regression analysis to determine the relative contribution of each predictor variable to the total variance explained by the model. This method decomposes the multiple correlation coefficient to assess how much each predictor contributes, accounting for the multicollinearity among predictors. It provides a clear and interpretable measure of the importance of each feature.</p>
<p><strong>Mathematical Equation</strong>: To compute Johnson’s relative weights, we follow these steps:</p>
<p>Here is the text formatted for Quarto, ensuring that the math equations render correctly:</p>
<ol type="1">
<li><p>Calculate the correlation matrix ((R)) for the predictors: <span class="math display">\[
R = \text{corr}(X)
\]</span></p></li>
<li><p>Compute the correlation vector ((r_{yx})) between the predictors and the dependent variable ((y)): <span class="math display">\[
r_{yx} = \text{corr}(X, y)
\]</span></p></li>
<li><p>Perform an eigenvalue decomposition of the correlation matrix to obtain eigenvalues (()) and eigenvectors ((V)): <span class="math display">\[
R = V \Lambda V^{-1}
\]</span></p></li>
<li><p>Calculate the squared semipartial correlations ((r_{*}^{2})) of each predictor with the dependent variable, adjusting for multicollinearity: <span class="math display">\[
y^{*} = V^{-1} r_{yx}
\]</span> <span class="math display">\[
r_{*}^{2} = y^{*} y^{* T}
\]</span></p></li>
<li><p>Normalize these values to get the relative weights ((w_i)): <span class="math display">\[
w_i = \frac{r_{*i}^2}{\sum_{i} r_{*i}^2}
\]</span></p></li>
</ol>
<p><strong>Implementation</strong>: Here is the code used to compute Johnson’s relative weights:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to calculate Johnson's relative weights</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_relative_weights(X, y):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    corr_matrix <span class="op">=</span> np.corrcoef(X, rowvar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    r_yx <span class="op">=</span> np.corrcoef(X, y, rowvar<span class="op">=</span><span class="va">False</span>)[<span class="op">-</span><span class="dv">1</span>, :<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    r_sq <span class="op">=</span> r_yx <span class="op">@</span> np.linalg.inv(corr_matrix) <span class="op">@</span> r_yx.T</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    eigenvalues, eigenvectors <span class="op">=</span> np.linalg.eig(corr_matrix)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    y_star <span class="op">=</span> r_yx <span class="op">@</span> eigenvectors <span class="op">/</span> np.sqrt(eigenvalues)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    r_star_sq <span class="op">=</span> y_star <span class="op">@</span> y_star.T</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    raw_relative_weights <span class="op">=</span> r_star_sq <span class="op">/</span> r_sq</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    relative_weights <span class="op">=</span> raw_relative_weights <span class="op">/</span> raw_relative_weights.<span class="bu">sum</span>()</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.Series(relative_weights, index<span class="op">=</span>X.columns)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate Johnson's relative weights</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>johnsons_weights <span class="op">=</span> calculate_relative_weights(X, y)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the relative weights</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>johnsons_weights.sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Results</strong>: The Johnson’s relative weights for the features are as follows:</p>
<table class="table">
<thead>
<tr class="header">
<th>Feature</th>
<th>Relative Weight</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>impact</td>
<td>0.426861</td>
</tr>
<tr class="even">
<td>trust</td>
<td>0.313095</td>
</tr>
<tr class="odd">
<td>service</td>
<td>0.175486</td>
</tr>
<tr class="even">
<td>appealing</td>
<td>0.028907</td>
</tr>
<tr class="odd">
<td>differs</td>
<td>0.021672</td>
</tr>
<tr class="even">
<td>easy</td>
<td>0.011538</td>
</tr>
<tr class="odd">
<td>build</td>
<td>0.009565</td>
</tr>
<tr class="even">
<td>popular</td>
<td>0.008361</td>
</tr>
<tr class="odd">
<td>brand</td>
<td>0.003803</td>
</tr>
<tr class="even">
<td>rewarding</td>
<td>0.000711</td>
</tr>
</tbody>
</table>
<p>These results show that <code>impact</code>, <code>trust</code>, and <code>service</code> have the highest relative weights, indicating that they are the most significant features in explaining the variance in customer satisfaction. This further confirms the findings from the previous methods, highlighting the importance of these features.</p>
</section>
<section id="mean-decrease-in-gini-coefficient" class="level4">
<h4 class="anchored" data-anchor-id="mean-decrease-in-gini-coefficient">3.6 Mean Decrease in Gini Coefficient</h4>
<p><strong>Description</strong>: The mean decrease in Gini coefficient is a metric used in Random Forest models to measure the importance of each feature. In the context of decision trees, the Gini impurity measures the likelihood of an incorrect classification of a randomly chosen element. The mean decrease in Gini coefficient indicates how much each feature contributes to reducing the impurity, with higher values signifying greater importance. This metric helps in identifying the most influential features in predicting the target variable.</p>
<p><strong>Implementation</strong>: To calculate the mean decrease in Gini coefficient, we followed these steps:</p>
<ol type="1">
<li><p>Train a Random Forest model using the dataset.</p></li>
<li><p>Extract the feature importances from the model, which represent the mean decrease in Gini coefficient for each feature.</p></li>
</ol>
<p>Here is a snippet of the code used:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Train a random forest model</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X, y)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate feature importances (mean decrease in Gini coefficient)</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>rf_importances <span class="op">=</span> pd.Series(rf_model.feature_importances_, index<span class="op">=</span>X.columns)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the feature importances</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>rf_importances.sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Results</strong>: The mean decrease in Gini coefficient for the features are as follows:</p>
<table class="table">
<thead>
<tr class="header">
<th>Feature</th>
<th>Mean Decrease in Gini</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>brand</td>
<td>0.266676</td>
</tr>
<tr class="even">
<td>trust</td>
<td>0.090872</td>
</tr>
<tr class="odd">
<td>popular</td>
<td>0.089204</td>
</tr>
<tr class="even">
<td>build</td>
<td>0.086096</td>
</tr>
<tr class="odd">
<td>rewarding</td>
<td>0.082906</td>
</tr>
<tr class="even">
<td>easy</td>
<td>0.081621</td>
</tr>
<tr class="odd">
<td>service</td>
<td>0.081490</td>
</tr>
<tr class="even">
<td>impact</td>
<td>0.079966</td>
</tr>
<tr class="odd">
<td>differs</td>
<td>0.072536</td>
</tr>
<tr class="even">
<td>appealing</td>
<td>0.068633</td>
</tr>
</tbody>
</table>
<p>These results show that <code>brand</code>, <code>trust</code>, and <code>popular</code> have the highest mean decrease in Gini coefficient values, suggesting they are the most influential features in reducing impurity in the Random Forest model. This indicates that these features play a significant role in predicting customer satisfaction in the context of this model.</p>
</section>
<section id="xgboost-feature-importance" class="level4">
<h4 class="anchored" data-anchor-id="xgboost-feature-importance">3.7 XGBoost Feature Importance</h4>
<p><strong>Description</strong>: XGBoost is a powerful gradient boosting framework widely used for supervised learning tasks. It builds an ensemble of decision trees in a sequential manner, where each tree corrects the errors of the previous ones. Feature importance in XGBoost is determined based on the improvement in the model’s performance each feature provides when it is used to split the data. This can be quantified by metrics such as gain, cover, and frequency. In this analysis, we focus on the gain metric, which measures the improvement in accuracy brought by a feature to the branches it is on.</p>
<p><strong>Implementation</strong>: To derive feature importance using the XGBoost model, we followed these steps:</p>
<ol type="1">
<li><p>Train an XGBoost regression model using the dataset.</p></li>
<li><p>Extract the feature importances from the model based on the gain metric.</p></li>
</ol>
<p>Here is a snippet of the code used:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Train an XGBoost model</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="op">=</span> xgb.XGBRegressor(objective<span class="op">=</span><span class="st">'reg:squarederror'</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>xgb_model.fit(X, y)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Get feature importances from the XGBoost model</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>xgb_importances <span class="op">=</span> pd.Series(xgb_model.feature_importances_, index<span class="op">=</span>X.columns)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the feature importances</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>xgb_importances.sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Results</strong>: The XGBoost feature importance values for the features are as follows:</p>
<table class="table">
<thead>
<tr class="header">
<th>Feature</th>
<th>XGBoost Feature Importance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>trust</td>
<td>0.200411</td>
</tr>
<tr class="even">
<td>impact</td>
<td>0.155718</td>
</tr>
<tr class="odd">
<td>service</td>
<td>0.093874</td>
</tr>
<tr class="even">
<td>brand</td>
<td>0.093745</td>
</tr>
<tr class="odd">
<td>build</td>
<td>0.079080</td>
</tr>
<tr class="even">
<td>popular</td>
<td>0.077944</td>
</tr>
<tr class="odd">
<td>differs</td>
<td>0.076992</td>
</tr>
<tr class="even">
<td>rewarding</td>
<td>0.076080</td>
</tr>
<tr class="odd">
<td>appealing</td>
<td>0.074944</td>
</tr>
<tr class="even">
<td>easy</td>
<td>0.071211</td>
</tr>
</tbody>
</table>
<p>These results indicate that <code>trust</code>, <code>impact</code>, and <code>service</code> have the highest feature importance values in the XGBoost model, suggesting they are the most influential features in predicting customer satisfaction. This is consistent with the findings from other methods, reinforcing the importance of these features.</p>
</section>
</section>
<section id="comparative-analysis" class="level3">
<h3 class="anchored" data-anchor-id="comparative-analysis">4. Comparative Analysis</h3>
<section id="summary-table" class="level4">
<h4 class="anchored" data-anchor-id="summary-table">Summary Table</h4>
<p>Below is the summary table that consolidates the importance metrics from all the methods discussed:</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 10%">
<col style="width: 18%">
<col style="width: 7%">
<col style="width: 11%">
<col style="width: 13%">
<col style="width: 16%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Pearson Correlations</th>
<th>Standardized Regression Coefficients</th>
<th>Shapley Values</th>
<th>Permutation Importance</th>
<th>Johnson’s Relative Weights</th>
<th>Mean Decrease in Gini Coefficient</th>
<th>XGBoost Feature Importance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>brand</td>
<td>-0.049296</td>
<td>0.012083</td>
<td>0.010036</td>
<td>0.000438</td>
<td>0.003803</td>
<td>0.266676</td>
<td>0.093745</td>
</tr>
<tr class="even">
<td>trust</td>
<td>0.255706</td>
<td>0.135680</td>
<td>0.136622</td>
<td>0.027346</td>
<td>0.313095</td>
<td>0.090872</td>
<td>0.200411</td>
</tr>
<tr class="odd">
<td>build</td>
<td>0.191896</td>
<td>0.022809</td>
<td>0.022562</td>
<td>0.000988</td>
<td>0.009565</td>
<td>0.086096</td>
<td>0.079080</td>
</tr>
<tr class="even">
<td>differs</td>
<td>0.184801</td>
<td>0.033271</td>
<td>0.029423</td>
<td>0.001756</td>
<td>0.021672</td>
<td>0.072536</td>
<td>0.076992</td>
</tr>
<tr class="odd">
<td>easy</td>
<td>0.212985</td>
<td>0.026449</td>
<td>0.026634</td>
<td>0.001021</td>
<td>0.011538</td>
<td>0.081621</td>
<td>0.071211</td>
</tr>
<tr class="even">
<td>appealing</td>
<td>0.207997</td>
<td>0.041336</td>
<td>0.040723</td>
<td>0.002693</td>
<td>0.028907</td>
<td>0.068633</td>
<td>0.074944</td>
</tr>
<tr class="odd">
<td>rewarding</td>
<td>0.194561</td>
<td>0.006482</td>
<td>0.006399</td>
<td>0.000125</td>
<td>0.000711</td>
<td>0.082906</td>
<td>0.076080</td>
</tr>
<tr class="even">
<td>popular</td>
<td>0.171425</td>
<td>0.020254</td>
<td>0.020249</td>
<td>0.000474</td>
<td>0.008361</td>
<td>0.089204</td>
<td>0.077944</td>
</tr>
<tr class="odd">
<td>service</td>
<td>0.251098</td>
<td>0.103069</td>
<td>0.101534</td>
<td>0.016385</td>
<td>0.175486</td>
<td>0.081490</td>
<td>0.093874</td>
</tr>
<tr class="even">
<td>impact</td>
<td>0.254539</td>
<td>0.150809</td>
<td>0.130991</td>
<td>0.033393</td>
<td>0.426861</td>
<td>0.079966</td>
<td>0.155718</td>
</tr>
</tbody>
</table>
</section>
<section id="discussion" class="level4">
<h4 class="anchored" data-anchor-id="discussion">Discussion</h4>
<p>The comparative analysis of different feature importance methods reveals both consistencies and discrepancies. Here are some key observations:</p>
<ol type="1">
<li><strong>Consistencies</strong>:
<ul>
<li><strong>Trust, Impact, and Service</strong>: These features consistently rank high across multiple methods. <code>Trust</code> has the highest Shapley value and XGBoost feature importance, and it also ranks high in Pearson correlations and Johnson’s relative weights. <code>Impact</code> similarly ranks high across Shapley values, standardized regression coefficients, and Johnson’s relative weights. <code>Service</code> is also consistently important across these methods.</li>
<li><strong>Brand</strong>: This feature shows a high mean decrease in Gini coefficient, indicating it significantly reduces impurity in the Random Forest model. However, it has low importance in other methods, suggesting that its influence might be model-specific.</li>
</ul></li>
<li><strong>Discrepancies</strong>:
<ul>
<li><strong>Popular</strong>: This feature shows a high mean decrease in Gini coefficient but low importance in other methods. This discrepancy highlights the need to consider multiple metrics to get a comprehensive view of feature importance.</li>
<li><strong>Build and Rewarding</strong>: These features have relatively low importance across most methods, except for the mean decrease in Gini coefficient where <code>Rewarding</code> shows moderate importance.</li>
</ul></li>
</ol>
</section>
<section id="insights" class="level4">
<h4 class="anchored" data-anchor-id="insights">Insights</h4>
<p>The analysis highlights that <code>trust</code>, <code>impact</code>, and <code>service</code> are the most important features for customer satisfaction with payment cards. This suggests that customers value cards from trusted brands that make a significant positive impact on their lives and provide excellent customer service. These insights can guide financial institutions in prioritizing these aspects to enhance customer satisfaction.</p>
<p>Additionally, the discrepancies observed in features like <code>brand</code> and <code>popular</code> suggest that feature importance can vary depending on the method used. Therefore, it is beneficial to use multiple methods to gain a holistic understanding of what drives customer satisfaction.</p>
</section>
<section id="business-context" class="level4">
<h4 class="anchored" data-anchor-id="business-context">Business Context</h4>
<p>To make the analysis more relatable to business applications, we mapped each variable to a corresponding customer satisfaction question. This mapping helps in understanding the business context and the specific aspects of payment cards that are most important to customers. Here is the mapping:</p>
<ul>
<li><strong>Is offered by a brand I trust</strong> -&gt; <code>trust</code></li>
<li><strong>Helps build credit quickly</strong> -&gt; <code>build</code></li>
<li><strong>Is different from other cards</strong> -&gt; <code>differs</code></li>
<li><strong>Is easy to use</strong> -&gt; <code>easy</code></li>
<li><strong>Has appealing benefits or rewards</strong> -&gt; <code>appealing</code></li>
<li><strong>Rewards me for responsible usage</strong> -&gt; <code>rewarding</code></li>
<li><strong>Is used by a lot of people</strong> -&gt; <code>popular</code></li>
<li><strong>Provides outstanding customer service</strong> -&gt; <code>service</code></li>
<li><strong>Makes a difference in my life</strong> -&gt; <code>impact</code></li>
</ul>
<p>Below is the final table with percentages instead of decimals and incorporating the business-related question likely associated with each variable:</p>
<table class="table">
<colgroup>
<col style="width: 17%">
<col style="width: 9%">
<col style="width: 16%">
<col style="width: 6%">
<col style="width: 10%">
<col style="width: 12%">
<col style="width: 14%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th>Question</th>
<th>Pearson Correlations</th>
<th>Standardized Regression Coefficients</th>
<th>Shapley Values</th>
<th>Permutation Importance</th>
<th>Johnson’s Relative Weights</th>
<th>Mean Decrease in Gini Coefficient</th>
<th>XGBoost Feature Importance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Is offered by a brand I trust</td>
<td>-4.9%</td>
<td>1.2%</td>
<td>1.0%</td>
<td>0.04%</td>
<td>0.4%</td>
<td>26.7%</td>
<td>9.4%</td>
</tr>
<tr class="even">
<td>Helps build credit quickly</td>
<td>19.2%</td>
<td>2.3%</td>
<td>2.3%</td>
<td>0.1%</td>
<td>1.0%</td>
<td>8.6%</td>
<td>7.9%</td>
</tr>
<tr class="odd">
<td>Is different from other cards</td>
<td>18.5%</td>
<td>3.3%</td>
<td>2.9%</td>
<td>0.2%</td>
<td>2.2%</td>
<td>7.3%</td>
<td>7.7%</td>
</tr>
<tr class="even">
<td>Is easy to use</td>
<td>21.3%</td>
<td>2.6%</td>
<td>2.7%</td>
<td>0.1%</td>
<td>1.2%</td>
<td>8.2%</td>
<td>7.1%</td>
</tr>
<tr class="odd">
<td>Has appealing benefits or rewards</td>
<td>20.8%</td>
<td>4.1%</td>
<td>4.1%</td>
<td>0.3%</td>
<td>2.9%</td>
<td>6.9%</td>
<td>7.5%</td>
</tr>
<tr class="even">
<td>Rewards me for responsible usage</td>
<td>19.5%</td>
<td>0.6%</td>
<td>0.6%</td>
<td>0.0%</td>
<td>0.1%</td>
<td>8.3%</td>
<td>7.6%</td>
</tr>
<tr class="odd">
<td>Is used by a lot of people</td>
<td>17.1%</td>
<td>2.0%</td>
<td>2.0%</td>
<td>0.0%</td>
<td>0.8%</td>
<td>8.9%</td>
<td>7.8%</td>
</tr>
<tr class="even">
<td>Provides outstanding customer service</td>
<td>25.1%</td>
<td>10.3%</td>
<td>10.2%</td>
<td>1.6%</td>
<td>17.5%</td>
<td>8.1%</td>
<td>9.4%</td>
</tr>
<tr class="odd">
<td>Makes a difference in my life</td>
<td>25.5%</td>
<td>15.1%</td>
<td>13.1%</td>
<td>3.3%</td>
<td>42.7%</td>
<td>8.0%</td>
<td>15.6%</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">5. Conclusion</h3>
<section id="summary" class="level4">
<h4 class="anchored" data-anchor-id="summary">Summary</h4>
<p>In this analysis, we explored multiple methods to determine the importance of various features in predicting customer satisfaction with payment cards. The methods included Pearson correlations, standardized regression coefficients, Shapley values, permutation importance, Johnson’s relative weights, mean decrease in Gini coefficient, and XGBoost feature importance. Consistently across these methods, <code>trust</code>, <code>impact</code>, and <code>service</code> emerged as the most significant features influencing customer satisfaction. These findings were further contextualized by mapping each feature to a specific customer satisfaction question.</p>
</section>
<section id="implications" class="level4">
<h4 class="anchored" data-anchor-id="implications">Implications</h4>
<p>The insights from this analysis have several implications for businesses in the financial sector:</p>
<ol type="1">
<li><p><strong>Focus on Trust</strong>: Building and maintaining trust is crucial. Companies should prioritize transparency, reliability, and security to enhance trust among customers.</p></li>
<li><p><strong>Customer Impact</strong>: Payment cards should offer tangible benefits that positively impact customers’ lives. This could include unique rewards, financial benefits, or services that simplify financial management.</p></li>
<li><p><strong>Outstanding Service</strong>: Providing exceptional customer service is key to satisfaction. Businesses should invest in training customer service representatives, offering multiple support channels, and ensuring prompt and effective resolution of issues.</p></li>
</ol>
<p>By focusing on these areas, companies can better meet customer needs, enhance satisfaction, and foster loyalty.</p>
</section>
<section id="future-work" class="level4">
<h4 class="anchored" data-anchor-id="future-work">Future Work</h4>
<p>There are several avenues for further research and additional analyses:</p>
<ol type="1">
<li><p><strong>Longitudinal Studies</strong>: Conducting longitudinal studies to track changes in customer satisfaction over time and understanding how feature importance evolves.</p></li>
<li><p><strong>Segmentation Analysis</strong>: Performing segmentation analysis to identify differences in feature importance across different customer demographics or segments.</p></li>
<li><p><strong>Advanced Modeling Techniques</strong>: Exploring advanced modeling techniques such as deep learning or ensemble methods to validate and potentially enhance the findings.</p></li>
<li><p><strong>Customer Feedback Integration</strong>: Integrating direct customer feedback and sentiment analysis to enrich the understanding of customer satisfaction drivers.</p></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">

<div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>